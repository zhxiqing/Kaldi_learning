# NNet3 学习笔记

## 目录

* [背景简介](#背景简介)

* [nnet3组成部分](#nnet3组成部分)

* [nnet3基础结构](#nnet3基础结构)

## 背景简介

Kaldi 目前对于神经网络的支持共有三个版本，nnet1、nnet2和nnet3。nnet1由Karel Vesely维护，源码位于src/nnet和src/nnetbin。nnet2主要由Povey大神负责维护，脱胎自nnet1的早起代码，源码位于src/nnet2和src/nnet2bin。自nnet2起就支持多核多机多卡的训练。nnet2采用的是固定epoch数和参数平均的方式进行训练。nnet3是Povey大神推荐的学习路径，很多nnet2中的功能特性都将迁移至nnet3，nnet3的源码位于src/nnet3和src/nnet3bin。

nnet1和nnet2都采用基于组件的方式，即，一个神经网络的构成就是相关组件的堆叠，每个组件都对应神经网络的一层(layer)的一部分。比如由仿射变换和非线性组成的一层。这些组件有一个前传函数和反向传播函数，都是为了方便在小batch上进行操作。在nnet2中网络引入了时间序号，为了方便在时间维度上进行索引和分片，这些操作能够方便的实现一些网络架构，比如TDNN。

nnet3的目的在于支持nnet1和nnet2中的拓扑结构，同时，致力于实现以配置文件的方式书写网络架构，不需要编写代码就能够实现新的网络。

## nnet3组成部分

nnet3不再是一堆组件的序列组合，而是采用了图的结构，因此一个"nnet3"的神经网络应该由以下两部分组成:

	1. 一组有命名的组件，可以是无序的。

	2. 图结构的表示，以及描述组件之间是如何结合在一起的“胶水”。

图通过组件的名字引用组件，而“胶水”的作用在于，举个栗子，t时刻的状态取决于t-1时刻的状态，如何将这两个时刻的状态进行连接。图的结构、各种组件以及网络的输入共同决定了网络的输出，它们用于生成计算图，生成计算图是一个重要的编译步骤。计算图是一个无环图，图中的每个节点都由神经网络中的节点(或者说神经网络中的一个layer)以及一些附加的索引唯一确定，举栗说明，这些索引可以是表示时间的t，或者是样本在mini-batch中的索引n, 或者是在卷积相关操作会用到的额外索引x。

用更数学的语言来描述，我们先定义三元索引*Index* $(t,n,x)$。同时定义复合索引*Cindex* $(nodeIndex,Index)$, 这里的*nodeIndex*对应了神经网络中的节点。我们的实际计算流程就表示为定义在复合索引*Cindex*上的有向无环图。

至此，使用神经网络的步骤如下所示:
	
	* 用户提供*ComputationRequest*告知哪些索引和输入是可用的，以及需要什么输出。
	
	* *ComputationRequest*和神经网络共同编译成一组命令序列构成*NnetComputation*。

	* *NnetComputation*会进行计算速度的优化,类似于编译器优化。

	* *NnetComputer*类接受矩阵格式的数据输入，并完成*NnetComputation*的实际计算，返回矩阵格式的数据输出。

## nnet3基础结构

### Index

上面已经描述了*Index*的组成，它是一个三元组$(t,n,x)$，$n$是minibatch的索引，$t$是时间的索引，x是留预留给卷积相关操作的索引，目前将其置0。在网络计算的过程中，向量也是视作矩阵来计算的，如1024维的向量即对应了有1024列的矩阵。
